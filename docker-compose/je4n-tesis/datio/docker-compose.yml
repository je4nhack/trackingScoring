version: "2"

services:
  zookeeper:
    image: zookeeper:3.4.10
    container_name: zookeeper
    ports:
      - 2181:2181

  kafka:
    image: wurstmeister/kafka:0.10.1.0
    container_name: kafka
    ports:
      - 9092:9092
    environment:
      HOSTNAME_COMMAND: "route -n | awk '/UG[ \t]/{print $$2}'"
      KAFKA_ADVERTISED_PORT: "9092"
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
    links:
      - zookeeper

  hadoop:
    build: ./hadoop
    container_name: hadoop
    ports:
      - 9000:9000
      - 50070:50070
      - 50075:50075
    command: bash -c "chmod +x /etc/bootstrap.sh && sh /etc/bootstrap.sh -d"

  master:
    build: ./spark
    command: bin/spark-class org.apache.spark.deploy.master.Master -h master
    container_name: spark_master
    hostname: master
    environment:
      MASTER: spark://master:7077
      SPARK_CONF_DIR: /conf
      SPARK_PUBLIC_DNS: localhost
    links:
      - hadoop
      - kafka
    expose:
      - 7001
      - 7002
      - 7003
      - 7004
      - 7005
      - 7006
      - 7077
      - 6066
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 18080:8080
      - 5005:5005 #For remote debug
    volumes:
      - ./spark/conf/master:/conf:z
      - ./spark/classpath:/classpath:z

  worker:
    build: ./spark
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077
    container_name: spark_worker
    hostname: worker
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
    links:
      - master
      - hadoop
      - kafka
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 8081:8081
    volumes:
      - ./spark/conf/worker:/conf:z
      - ./spark/classpath:/classpath:z

networks:
  default:
    driver: bridge