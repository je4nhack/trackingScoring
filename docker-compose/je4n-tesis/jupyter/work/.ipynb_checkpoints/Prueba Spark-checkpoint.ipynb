{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import java.sql.Date\n",
    "import java.text.SimpleDateFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.sql.AnalysisException\n",
       "Message: Path does not exist: file:/home/jovyan/work jupyter/all-spark-notebook/prueba.txt;\n",
       "StackTrace:   at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:558)\n",
       "  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:545)\n",
       "  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n",
       "  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n",
       "  at scala.collection.immutable.List.foreach(List.scala:392)\n",
       "  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n",
       "  at scala.collection.immutable.List.flatMap(List.scala:355)\n",
       "  at org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:545)\n",
       "  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:359)\n",
       "  at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n",
       "  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
       "  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:615)\n",
       "  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema = StructType(\n",
    "    Array(\n",
    "      StructField(\"COD_PERIODO\", StringType, true),\n",
    "      StructField(\"TIPO_DOCUMENTO\", StringType, true),\n",
    "      StructField(\"NUM_DOCUMENTO\", StringType, true),\n",
    "      StructField(\"FECHPROC\", StringType, true),\n",
    "      StructField(\"CLIENTE\", StringType, true),\n",
    "      StructField(\"FRONTGR1\", DoubleType, true),\n",
    "      StructField(\"FRONTGR2\", DoubleType, true),\n",
    "      StructField(\"FRONTGR3\", DoubleType, true),\n",
    "      StructField(\"FRONTGR4\", DoubleType, true),\n",
    "      StructField(\"FRONTGR5\", DoubleType, true),\n",
    "      StructField(\"FRONTGR6\", DoubleType, true),\n",
    "      StructField(\"FRONTGR7\", DoubleType, true),\n",
    "      StructField(\"CONSTANTE_K\", DoubleType, true),\n",
    "      StructField(\"ALTA\", DoubleType, true),\n",
    "      StructField(\"ANTIG\", DoubleType, true),\n",
    "      StructField(\"PRPOSTOPR\", DoubleType, true),\n",
    "      StructField(\"PRANTPEPR\", DoubleType, true),\n",
    "      StructField(\"SOBPOSTOD\", DoubleType, true),\n",
    "      StructField(\"DESPOSTOD\", DoubleType, true),\n",
    "      StructField(\"PACOMP01\", DoubleType, true),\n",
    "      StructField(\"MESIMPVIG\", DoubleType, true),\n",
    "      StructField(\"COMPST06\", DoubleType, true),\n",
    "      StructField(\"TCRUSVIG\", DoubleType, true),\n",
    "      StructField(\"SOBRUSVIG\", DoubleType, true),\n",
    "      StructField(\"MESCOMP12\", DoubleType, true),\n",
    "      StructField(\"TCMUSVRR\", DoubleType, true),\n",
    "      StructField(\"SOBMPOVEN\", DoubleType, true),\n",
    "      StructField(\"TCCOMP23\", DoubleType, true),\n",
    "      StructField(\"DESCOMP23\", DoubleType, true),\n",
    "      StructField(\"CLADEU23\", DoubleType, true),\n",
    "      StructField(\"TENCAST23\", StringType, true), //\n",
    "      StructField(\"TODNUMVIG\", DoubleType, true),\n",
    "      StructField(\"SOBRUSVEN\", DoubleType, true),\n",
    "      StructField(\"PACOMP06\", DoubleType, true),\n",
    "      StructField(\"ARRPOSVRR\", DoubleType, true),\n",
    "      StructField(\"TCMUCVIG\", DoubleType, true),\n",
    "      StructField(\"PRIMPPETO\", DoubleType, true),\n",
    "      StructField(\"P_ALTA\", DoubleType, true),\n",
    "      StructField(\"P_ANTIG\", DoubleType, true),\n",
    "      StructField(\"P_PRPOSTOPR\", DoubleType, true),\n",
    "      StructField(\"P_PRANTPEPR\", DoubleType, true),\n",
    "      StructField(\"P_SOBPOSTOD\", DoubleType, true),\n",
    "      StructField(\"P_DESPOSTOD\", DoubleType, true),\n",
    "      StructField(\"P_PACOMP01\", DoubleType, true),\n",
    "      StructField(\"P_SAL_MESIMPVIG\", DoubleType, true),\n",
    "      StructField(\"P_ACU_COMPST06\", DoubleType, true),\n",
    "      StructField(\"P_TCRUSVIG\", DoubleType, true),\n",
    "      StructField(\"P_SOBRUSVIG\", DoubleType, true),\n",
    "      StructField(\"P_MESCOMP12\", DoubleType, true),\n",
    "      StructField(\"P_TCMUSVRR\", DoubleType, true),\n",
    "      StructField(\"P_SOBMPOVEN\", DoubleType, true),\n",
    "      StructField(\"P_TCCOMP23\", DoubleType, true),\n",
    "      StructField(\"P_DESCOMP23\", DoubleType, true),\n",
    "      StructField(\"P_CLADEU23\", DoubleType, true),\n",
    "      StructField(\"P_TENCAST23\", DoubleType, true),\n",
    "      StructField(\"P_CONT_TODNUMVIG\", DoubleType, true),\n",
    "      StructField(\"P_SOBRUSVEN\", DoubleType, true),\n",
    "      StructField(\"P_PACOMP06\", DoubleType, true),\n",
    "      StructField(\"P_ARRPOSVRR\", DoubleType, true),\n",
    "      StructField(\"P_TCMUCVIG\", DoubleType, true),\n",
    "      StructField(\"P_PRIMPPETO\", DoubleType, true),\n",
    "      StructField(\"PUNT_FINAL\", DoubleType, true),\n",
    "      StructField(\"PROBABILIDAD\", DoubleType, true),\n",
    "      StructField(\"GRRIESGO\", StringType, true),\n",
    "      StructField(\"FLG_BUENO_MALO\", StringType, true),\n",
    "      StructField(\"FLG_BUENO_MALO_60D\", StringType, true),\n",
    "      StructField(\"FLG_100NOR\", StringType, true)\n",
    "    )\n",
    "  )\n",
    "\n",
    "  var df = spark.read.\n",
    "    option(\"header\", \"true\").\n",
    "    option(\"delimiter\", \",\").\n",
    "    schema(schema).\n",
    "    csv(\"/home/jovyan/work jupyter/all-spark-notebook/prueba.txt\")\n",
    "\n",
    "  df = df.withColumn(\"cutoff_date\", unix_timestamp(trim(col(\"COD_PERIODO\")), \"yyyyMM\").cast(TimestampType).cast(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n",
       "paintDf: (df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def paintDf(df: DataFrame): DataFrame = df.select(df.columns.map(col(_).cast(\"string\")): _*).na.fill(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "An error occurred converting DataFrame to html.\n",
       "<console>:41: error: not found: value df\n",
       "       paintDf(df)\n",
       "               ^\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%Dataframe\n",
    "paintDf(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from file:/home/jovyan/work/mongo-java-driver-3.9.0.jar\n",
      "Finished download of mongo-java-driver-3.9.0.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar file:/home/jovyan/work/mongo-java-driver-3.9.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from file:/home/jovyan/work/mongo-spark-connector_2.11-2.4.0.jar\n",
      "Finished download of mongo-spark-connector_2.11-2.4.0.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar file:/home/jovyan/work/mongo-spark-connector_2.11-2.4.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparkSession = org.apache.spark.sql.SparkSession@573e84b7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@573e84b7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sparkSession = SparkSession.builder()\n",
    "      .appName(\"example-spark-scala-read-and-write-from-mongo\")\n",
    "      // Configuration for writing in a Mongo collection\n",
    "      .config(\"spark.mongodb.output.uri\", \"mongodb://192.168.43.73:27017/USRTANALYT\")\n",
    "      .config(\"spark.mongodb.output.collection\", \"scoringPeriod\")\n",
    "      // Configuration for reading a Mongo collection\n",
    "      .config(\"spark.mongodb.input.uri\", \"mongodb://192.168.43.73:27017/USRTANALYT\")\n",
    "      .config(\"spark.mongodb.input.collection\", \"scoring\")\n",
    "      // Type of Partitionner to use to transform Documents to dataframe\n",
    "      .config(\"spark.mongodb.input.partitioner\", \"MongoPaginateByCountPartitioner\")\n",
    "      // Number of partitions in the resulting dataframe\n",
    "      .config(\"spark.mongodb.input.partitionerOptions.MongoPaginateByCountPartitioner.numberOfPartitions\", \"1\")\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: java.lang.IllegalArgumentException\n",
       "Message: Missing database name. Set via the 'spark.mongodb.input.uri' or 'spark.mongodb.input.database' property\n",
       "StackTrace:   at com.mongodb.spark.config.MongoCompanionConfig$class.databaseName(MongoCompanionConfig.scala:260)\n",
       "  at com.mongodb.spark.config.ReadConfig$.databaseName(ReadConfig.scala:42)\n",
       "  at com.mongodb.spark.config.ReadConfig$.apply(ReadConfig.scala:69)\n",
       "  at com.mongodb.spark.config.ReadConfig$.apply(ReadConfig.scala:42)\n",
       "  at com.mongodb.spark.config.MongoCompanionConfig$class.apply(MongoCompanionConfig.scala:124)\n",
       "  at com.mongodb.spark.config.ReadConfig$.apply(ReadConfig.scala:42)\n",
       "  at com.mongodb.spark.config.MongoCompanionConfig$class.apply(MongoCompanionConfig.scala:113)\n",
       "  at com.mongodb.spark.config.ReadConfig$.apply(ReadConfig.scala:42)\n",
       "  at com.mongodb.spark.MongoSpark$Builder.build(MongoSpark.scala:234)\n",
       "  at com.mongodb.spark.MongoSpark$.load(MongoSpark.scala:84)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = MongoSpark.load(sparkSession)\n",
    "    df2.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
